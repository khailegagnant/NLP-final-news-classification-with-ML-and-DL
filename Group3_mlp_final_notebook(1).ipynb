{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BZCqhkfGwhbV"},"outputs":[],"source":["\n","import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import pandas as pd\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzn74qatHxjK","outputId":"3a915f35-0ceb-4f79-e5dd-e8f93d817c63"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Mar 26 21:34:50 2025       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA GeForce RTX 3060        On  | 00000000:02:00.0 Off |                  N/A |\n","| 38%   65C    P2             104W / 170W |   8416MiB / 12288MiB |    100%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|    0   N/A  N/A      1816      G   /usr/lib/xorg/Xorg                            9MiB |\n","|    0   N/A  N/A      2127      G   /usr/bin/gnome-shell                          3MiB |\n","|    0   N/A  N/A    480598      C   /home/long/longdata/.venv/bin/python       1846MiB |\n","|    0   N/A  N/A    675528      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675529      C   /home/long/longdata/.venv/bin/python        726MiB |\n","|    0   N/A  N/A    675530      C   /home/long/longdata/.venv/bin/python        132MiB |\n","|    0   N/A  N/A    675532      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675533      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675534      C   /home/long/longdata/.venv/bin/python        132MiB |\n","|    0   N/A  N/A    675535      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675536      C   /home/long/longdata/.venv/bin/python        140MiB |\n","|    0   N/A  N/A    675537      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675538      C   /home/long/longdata/.venv/bin/python        140MiB |\n","|    0   N/A  N/A    675539      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675540      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675543      C   /home/long/longdata/.venv/bin/python        132MiB |\n","|    0   N/A  N/A    675544      C   /home/long/longdata/.venv/bin/python        140MiB |\n","|    0   N/A  N/A    675547      C   /home/long/longdata/.venv/bin/python        286MiB |\n","|    0   N/A  N/A    675548      C   /home/long/longdata/.venv/bin/python        140MiB |\n","|    0   N/A  N/A    802675      C   /bin/python3                               2538MiB |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AwZn3suHxjN","outputId":"674ba2bd-0765-4b49-b3da-63c2e4d61fdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["[sudo] password for long: \n","sudo: a password is required\n","^C\n"]}],"source":["!nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 sudo kill -9 18885"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7ViKZ9e1EbC","outputId":"535443d5-a70d-40b1-a5ad-a14366dd3a1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_vYQDfb5--X"},"outputs":[],"source":["train  = pd.read_csv('vectorized_train_balanced.csv')\n","# test  = pd.read_csv('/content/drive/MyDrive/data for news classification/vectorized_test_new.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aabxaejH5paE","outputId":"58188f80-d146-43f4-ec5a-e34a982592bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-03-27 10:03:42.047371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-27 10:03:42.047426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-27 10:03:42.047480: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-27 10:03:42.057984: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-27 10:03:43.117154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivjjDPa1whbX"},"outputs":[],"source":["X = train.iloc[:, :-1]\n","y = train.iloc[:, -1]\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y,shuffle = True, test_size=0.2, random_state=20202)\n","label_encoder = LabelEncoder()\n","y_train = label_encoder.fit_transform(y_train)   # Now in range [0,09]\n","y_val = label_encoder.transform(y_val)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxdXGzkpHFb_","outputId":"328aaca1-0517-4f79-a850-fdd34868b97b"},"outputs":[{"data":{"text/plain":["2500"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpkeCWdj7WhP","outputId":"444d87fb-b16c-4734-e17c-ad44f8619100"},"outputs":[{"data":{"text/plain":["{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["set(y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qi4V57j22oci"},"outputs":[],"source":["del X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43ikn5D-3Uyj"},"outputs":[],"source":["del train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsLXpN39Hxjc"},"outputs":[],"source":["tf.debugging.disable_traceback_filtering()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZWeyq0h2m8G","outputId":"4d5458ab-72d7-47db-856e-3c5309e1a38a"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-03-26 13:35:46.361519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.569942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.571943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.574356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.580164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.580548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.823019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.823534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.823939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2025-03-26 13:35:46.824156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8342 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:02:00.0, compute capability: 8.6\n"]}],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","checkpoint = ModelCheckpoint(\n","    'only_vectorised/model.h5',\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=10,\n","    min_lr=0.0005)\n","\n","\n","model = Sequential()\n","model.add(Dense(4096, input_dim=X_train.shape[1], activation='relu'))\n","\n","# Hidden layers (6 in total)\n","model.add(Dense(2500, activation='relu'))\n","model.add(Dense(1250, activation='relu'))\n","model.add(Dense(800, activation='relu'))\n","model.add(Dense(500, activation='relu'))\n","model.add(Dense(200, activation='relu'))\n","# model.add(Dense(, activation='relu'))\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tJOHboa2R_G","outputId":"76c01cce-6acc-4726-9d96-f913c15d0683"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2025-03-26 13:35:54.432346: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2025-03-26 13:35:54.629311: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f809403eee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2025-03-26 13:35:54.629408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n","2025-03-26 13:35:54.659934: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2025-03-26 13:35:54.706753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n","2025-03-26 13:35:54.908937: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["384/386 [============================>.] - ETA: 0s - loss: 0.5686 - accuracy: 0.8186\n","Epoch 1: val_accuracy improved from -inf to 0.89929, saving model to only_vectorised/model.h5\n"]},{"name":"stderr","output_type":"stream","text":["/home/long/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["386/386 [==============================] - 17s 27ms/step - loss: 0.5672 - accuracy: 0.8190 - val_loss: 0.3671 - val_accuracy: 0.8993 - lr: 0.0010\n","Epoch 2/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9408\n","Epoch 2: val_accuracy did not improve from 0.89929\n","386/386 [==============================] - 7s 19ms/step - loss: 0.2147 - accuracy: 0.9405 - val_loss: 0.3785 - val_accuracy: 0.8953 - lr: 0.0010\n","Epoch 3/100\n","386/386 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9713\n","Epoch 3: val_accuracy did not improve from 0.89929\n","386/386 [==============================] - 8s 20ms/step - loss: 0.1060 - accuracy: 0.9713 - val_loss: 0.4515 - val_accuracy: 0.8959 - lr: 0.0010\n","Epoch 4/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9850\n","Epoch 4: val_accuracy did not improve from 0.89929\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0563 - accuracy: 0.9850 - val_loss: 0.5598 - val_accuracy: 0.8963 - lr: 0.0010\n","Epoch 5/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9876\n","Epoch 5: val_accuracy did not improve from 0.89929\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0529 - accuracy: 0.9877 - val_loss: 0.5853 - val_accuracy: 0.8981 - lr: 0.0010\n","Epoch 6/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9894\n","Epoch 6: val_accuracy did not improve from 0.89929\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0466 - accuracy: 0.9894 - val_loss: 0.6430 - val_accuracy: 0.8953 - lr: 0.0010\n","Epoch 7/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9935\n","Epoch 7: val_accuracy improved from 0.89929 to 0.90181, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 10s 25ms/step - loss: 0.0260 - accuracy: 0.9935 - val_loss: 0.7561 - val_accuracy: 0.9018 - lr: 0.0010\n","Epoch 8/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9947\n","Epoch 8: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0227 - accuracy: 0.9947 - val_loss: 0.7060 - val_accuracy: 0.8994 - lr: 0.0010\n","Epoch 9/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9937\n","Epoch 9: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.9281 - val_accuracy: 0.8934 - lr: 0.0010\n","Epoch 10/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9952\n","Epoch 10: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.8861 - val_accuracy: 0.9003 - lr: 0.0010\n","Epoch 11/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9946\n","Epoch 11: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0296 - accuracy: 0.9946 - val_loss: 0.9908 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 12/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9974\n","Epoch 12: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.9598 - val_accuracy: 0.8991 - lr: 5.0000e-04\n","Epoch 13/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9984\n","Epoch 13: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.0628 - val_accuracy: 0.8993 - lr: 5.0000e-04\n","Epoch 14/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9985\n","Epoch 14: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 1.1257 - val_accuracy: 0.9005 - lr: 5.0000e-04\n","Epoch 15/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9983\n","Epoch 15: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0028 - accuracy: 0.9983 - val_loss: 1.1795 - val_accuracy: 0.9005 - lr: 5.0000e-04\n","Epoch 16/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9982\n","Epoch 16: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 1.2584 - val_accuracy: 0.9006 - lr: 5.0000e-04\n","Epoch 17/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9984\n","Epoch 17: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 1.2503 - val_accuracy: 0.9002 - lr: 5.0000e-04\n","Epoch 18/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9986\n","Epoch 18: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.3494 - val_accuracy: 0.8994 - lr: 5.0000e-04\n","Epoch 19/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9984\n","Epoch 19: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 1.5033 - val_accuracy: 0.9000 - lr: 5.0000e-04\n","Epoch 20/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9982\n","Epoch 20: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 1.3900 - val_accuracy: 0.8990 - lr: 5.0000e-04\n","Epoch 21/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9983\n","Epoch 21: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0027 - accuracy: 0.9983 - val_loss: 1.5069 - val_accuracy: 0.8996 - lr: 5.0000e-04\n","Epoch 22/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9987\n","Epoch 22: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.6107 - val_accuracy: 0.9002 - lr: 5.0000e-04\n","Epoch 23/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9984\n","Epoch 23: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 1.5789 - val_accuracy: 0.8994 - lr: 5.0000e-04\n","Epoch 24/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9983\n","Epoch 24: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0026 - accuracy: 0.9983 - val_loss: 1.7220 - val_accuracy: 0.8994 - lr: 5.0000e-04\n","Epoch 25/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9982\n","Epoch 25: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 1.8258 - val_accuracy: 0.8996 - lr: 5.0000e-04\n","Epoch 26/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9983\n","Epoch 26: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 1.7477 - val_accuracy: 0.8991 - lr: 5.0000e-04\n","Epoch 27/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9982\n","Epoch 27: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 2.0858 - val_accuracy: 0.8987 - lr: 5.0000e-04\n","Epoch 28/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9981\n","Epoch 28: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 1.9884 - val_accuracy: 0.8990 - lr: 5.0000e-04\n","Epoch 29/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9985\n","Epoch 29: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 2.1596 - val_accuracy: 0.9005 - lr: 5.0000e-04\n","Epoch 30/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9983\n","Epoch 30: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 2.1211 - val_accuracy: 0.8991 - lr: 5.0000e-04\n","Epoch 31/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n","Epoch 31: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 1.9595 - val_accuracy: 0.8956 - lr: 5.0000e-04\n","Epoch 32/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9958\n","Epoch 32: val_accuracy did not improve from 0.90181\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0290 - accuracy: 0.9958 - val_loss: 1.4695 - val_accuracy: 0.8988 - lr: 5.0000e-04\n","Epoch 33/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9973\n","Epoch 33: val_accuracy improved from 0.90181 to 0.90625, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 9s 23ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 1.3418 - val_accuracy: 0.9062 - lr: 5.0000e-04\n","Epoch 34/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984\n","Epoch 34: val_accuracy did not improve from 0.90625\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.3792 - val_accuracy: 0.9048 - lr: 5.0000e-04\n","Epoch 35/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 35: val_accuracy improved from 0.90625 to 0.90655, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 9s 24ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 1.3511 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 36/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n","Epoch 36: val_accuracy did not improve from 0.90655\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 1.3549 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 37/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9984\n","Epoch 37: val_accuracy improved from 0.90655 to 0.90699, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 9s 23ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 1.4511 - val_accuracy: 0.9070 - lr: 5.0000e-04\n","Epoch 38/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 38: val_accuracy did not improve from 0.90699\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.4683 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 39/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 39: val_accuracy did not improve from 0.90699\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 1.4941 - val_accuracy: 0.9067 - lr: 5.0000e-04\n","Epoch 40/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 40: val_accuracy improved from 0.90699 to 0.90773, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 10s 25ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.5609 - val_accuracy: 0.9077 - lr: 5.0000e-04\n","Epoch 41/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 41: val_accuracy did not improve from 0.90773\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.5608 - val_accuracy: 0.9073 - lr: 5.0000e-04\n","Epoch 42/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n","Epoch 42: val_accuracy did not improve from 0.90773\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.5950 - val_accuracy: 0.9074 - lr: 5.0000e-04\n","Epoch 43/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 43: val_accuracy improved from 0.90773 to 0.90832, saving model to only_vectorised/model.h5\n","386/386 [==============================] - 10s 25ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 1.6785 - val_accuracy: 0.9083 - lr: 5.0000e-04\n","Epoch 44/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9984\n","Epoch 44: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.7015 - val_accuracy: 0.9064 - lr: 5.0000e-04\n","Epoch 45/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n","Epoch 45: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.7038 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 46/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9982\n","Epoch 46: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 1.7593 - val_accuracy: 0.9070 - lr: 5.0000e-04\n","Epoch 47/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 47: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.8216 - val_accuracy: 0.9079 - lr: 5.0000e-04\n","Epoch 48/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n","Epoch 48: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.8660 - val_accuracy: 0.9070 - lr: 5.0000e-04\n","Epoch 49/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 49: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.9064 - val_accuracy: 0.9077 - lr: 5.0000e-04\n","Epoch 50/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 50: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 2.0090 - val_accuracy: 0.9076 - lr: 5.0000e-04\n","Epoch 51/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 51: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.0617 - val_accuracy: 0.9070 - lr: 5.0000e-04\n","Epoch 52/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9984\n","Epoch 52: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 2.0313 - val_accuracy: 0.9071 - lr: 5.0000e-04\n","Epoch 53/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9982\n","Epoch 53: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 2.0646 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 54/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 54: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.1874 - val_accuracy: 0.9073 - lr: 5.0000e-04\n","Epoch 55/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9983\n","Epoch 55: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 2.1275 - val_accuracy: 0.9080 - lr: 5.0000e-04\n","Epoch 56/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 56: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 2.2968 - val_accuracy: 0.9079 - lr: 5.0000e-04\n","Epoch 57/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9982\n","Epoch 57: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 2.4202 - val_accuracy: 0.9074 - lr: 5.0000e-04\n","Epoch 58/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 58: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.4765 - val_accuracy: 0.9071 - lr: 5.0000e-04\n","Epoch 59/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 59: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.4795 - val_accuracy: 0.9073 - lr: 5.0000e-04\n","Epoch 60/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9986\n","Epoch 60: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 2.4489 - val_accuracy: 0.9076 - lr: 5.0000e-04\n","Epoch 61/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9981\n","Epoch 61: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 2.6457 - val_accuracy: 0.9071 - lr: 5.0000e-04\n","Epoch 62/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 62: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.5273 - val_accuracy: 0.9076 - lr: 5.0000e-04\n","Epoch 63/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9984\n","Epoch 63: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 2.8460 - val_accuracy: 0.9067 - lr: 5.0000e-04\n","Epoch 64/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 64: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 2.7139 - val_accuracy: 0.9068 - lr: 5.0000e-04\n","Epoch 65/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9984\n","Epoch 65: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 2.8062 - val_accuracy: 0.9067 - lr: 5.0000e-04\n","Epoch 66/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9981\n","Epoch 66: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0020 - accuracy: 0.9981 - val_loss: 2.8949 - val_accuracy: 0.9062 - lr: 5.0000e-04\n","Epoch 67/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 67: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 22ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.9356 - val_accuracy: 0.9071 - lr: 5.0000e-04\n","Epoch 68/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9981\n","Epoch 68: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 2.8436 - val_accuracy: 0.9062 - lr: 5.0000e-04\n","Epoch 69/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9984\n","Epoch 69: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 2.8776 - val_accuracy: 0.9065 - lr: 5.0000e-04\n","Epoch 70/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9971\n","Epoch 70: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0250 - accuracy: 0.9971 - val_loss: 1.9988 - val_accuracy: 0.9006 - lr: 5.0000e-04\n","Epoch 71/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9955\n","Epoch 71: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0297 - accuracy: 0.9955 - val_loss: 1.4452 - val_accuracy: 0.9009 - lr: 5.0000e-04\n","Epoch 72/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9976\n","Epoch 72: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 1.1575 - val_accuracy: 0.9018 - lr: 5.0000e-04\n","Epoch 73/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9981\n","Epoch 73: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0028 - accuracy: 0.9981 - val_loss: 1.4713 - val_accuracy: 0.9031 - lr: 5.0000e-04\n","Epoch 74/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9984\n","Epoch 74: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.4904 - val_accuracy: 0.9036 - lr: 5.0000e-04\n","Epoch 75/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9984\n","Epoch 75: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.5233 - val_accuracy: 0.9031 - lr: 5.0000e-04\n","Epoch 76/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9982\n","Epoch 76: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0020 - accuracy: 0.9982 - val_loss: 1.5973 - val_accuracy: 0.9034 - lr: 5.0000e-04\n","Epoch 77/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n","Epoch 77: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.6913 - val_accuracy: 0.9031 - lr: 5.0000e-04\n","Epoch 78/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9985\n","Epoch 78: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 21ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 1.5444 - val_accuracy: 0.9033 - lr: 5.0000e-04\n","Epoch 79/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9984\n","Epoch 79: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 1.5370 - val_accuracy: 0.9024 - lr: 5.0000e-04\n","Epoch 80/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9982\n","Epoch 80: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9982 - val_loss: 1.6139 - val_accuracy: 0.9023 - lr: 5.0000e-04\n","Epoch 81/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9985\n","Epoch 81: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.5600 - val_accuracy: 0.9025 - lr: 5.0000e-04\n","Epoch 82/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n","Epoch 82: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.5983 - val_accuracy: 0.9024 - lr: 5.0000e-04\n","Epoch 83/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 83: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.6408 - val_accuracy: 0.9031 - lr: 5.0000e-04\n","Epoch 84/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9984\n","Epoch 84: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 1.6217 - val_accuracy: 0.9034 - lr: 5.0000e-04\n","Epoch 85/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n","Epoch 85: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.6638 - val_accuracy: 0.9036 - lr: 5.0000e-04\n","Epoch 86/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 86: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.6709 - val_accuracy: 0.9036 - lr: 5.0000e-04\n","Epoch 87/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9984\n","Epoch 87: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.7392 - val_accuracy: 0.9037 - lr: 5.0000e-04\n","Epoch 88/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n","Epoch 88: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.7525 - val_accuracy: 0.9033 - lr: 5.0000e-04\n","Epoch 89/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 89: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 1.6448 - val_accuracy: 0.9031 - lr: 5.0000e-04\n","Epoch 90/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 90: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.7232 - val_accuracy: 0.9017 - lr: 5.0000e-04\n","Epoch 91/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9983\n","Epoch 91: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 1.8047 - val_accuracy: 0.9021 - lr: 5.0000e-04\n","Epoch 92/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9983\n","Epoch 92: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 1.5994 - val_accuracy: 0.9034 - lr: 5.0000e-04\n","Epoch 93/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9985\n","Epoch 93: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 19ms/step - loss: 0.0023 - accuracy: 0.9985 - val_loss: 1.7749 - val_accuracy: 0.9048 - lr: 5.0000e-04\n","Epoch 94/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9983\n","Epoch 94: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 1.9350 - val_accuracy: 0.9040 - lr: 5.0000e-04\n","Epoch 95/100\n","384/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9984\n","Epoch 95: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 19ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.9192 - val_accuracy: 0.9048 - lr: 5.0000e-04\n","Epoch 96/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 96: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 8s 20ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.9341 - val_accuracy: 0.9037 - lr: 5.0000e-04\n","Epoch 97/100\n","383/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9983\n","Epoch 97: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 2.0401 - val_accuracy: 0.9040 - lr: 5.0000e-04\n","Epoch 98/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n","Epoch 98: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.9472 - val_accuracy: 0.9040 - lr: 5.0000e-04\n","Epoch 99/100\n","386/386 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9984\n","Epoch 99: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 2.0366 - val_accuracy: 0.9045 - lr: 5.0000e-04\n","Epoch 100/100\n","385/386 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9984\n","Epoch 100: val_accuracy did not improve from 0.90832\n","386/386 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 2.0568 - val_accuracy: 0.9037 - lr: 5.0000e-04\n"]}],"source":["history = model.fit(X_train, y_train,\n","                    epochs=100,\n","                    batch_size=70,\n","                    validation_data=(X_val, y_val),\n","                    callbacks=[checkpoint, reduce_lr],\n","                    verbose = 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDUGPsCkhjxr"},"outputs":[],"source":["test = pd.read_csv('vectorized_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXUgsXrUHxjg","outputId":"20eabc1e-19ec-4b7b-b8ea-ebe716a52619"},"outputs":[{"data":{"text/plain":["{'Chinh tri Xa hoi',\n"," 'Doi song',\n"," 'Khoa hoc',\n"," 'Kinh doanh',\n"," 'Phap luat',\n"," 'Suc khoe',\n"," 'The gioi',\n"," 'The thao',\n"," 'Van hoa',\n"," 'Vi tinh'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["set(test.iloc[:,-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhirPw9QHxjh"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","\n","model = load_model('/home/long/longdata/chúa phù hộ người tên khải/model_25_12_80_50.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJe48Iny6D8e"},"outputs":[],"source":["\n","\n","\n","X_test = test.iloc[:, :-1]\n","y_test = test.iloc[:, -1]\n","\n","y_test = label_encoder.transform(y_test)\n","# Evaluate the model\n","pred_not_arg = model.predict(X_test)\n","pred = np.argmax(pred_not_arg,axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"id":"l4YeOmjgF39a","outputId":"df6e9409-e003-42ca-b6fa-34f4e1e9be37"},"outputs":[{"data":{"text/plain":["0\n","0    7958\n","7    6656\n","6    6550\n","8    6257\n","5    5506\n","3    5079\n","9    4405\n","4    3940\n","2    2171\n","1    1851\n","Name: count, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(pred).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"hO288TFpFmWL","outputId":"26be6d2d-260b-4795-9c80-d88e14e1c78e"},"outputs":[{"data":{"text/plain":["0\n","0    7567\n","6    6716\n","7    6667\n","8    6250\n","5    5417\n","3    5276\n","9    4560\n","4    3788\n","2    2096\n","1    2036\n","Name: count, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(y_test).value_counts()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4EfGktM7_C8"},"outputs":[],"source":["del test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8z43ffaH7rGA"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n","\n","\n","\n","\n","accuracy = accuracy_score(y_test, pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","\n","precision = precision_score(y_test, pred,average = 'weighted')\n","print(f\"Precision: {precision}\")\n","recall = recall_score(y_test, pred,average = 'weighted')\n","print(f\"Recall: {recall}\")\n","f1 = f1_score(y_test, pred,average = 'weighted')\n","print(f\"{f1}\")\n","\n","\n","\n","\n","\n","list_metric = [accuracy,precision,recall, f1]\n","\n","class_report = classification_report(y_test, pred)\n","print(\"clash royale\")\n","print(class_report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5bb41WbHxjl","outputId":"1ab47e5d-aa04-45bb-9e42-58f0c757f70a"},"outputs":[{"data":{"text/plain":["[0.9010779584301114,\n"," 0.9014500228662894,\n"," 0.9010779584301114,\n"," 0.9009997698826618]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["list_metric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LdOr0c9Hxjl"},"outputs":[],"source":["class_labels = label_encoder.inverse_transform(np.unique(y_test))\n","cm = confusion_matrix(y_test, pred, labels=np.unique(y_test))\n","import seaborn as sns\n","\n","def normalize_confusion_matrix(cm, norm='true'):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if norm == 'true':\n","            cm_normalized = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n","        elif norm == 'pred':\n","            cm_normalized = cm.astype(float) / cm.sum(axis=0, keepdims=True)\n","        elif norm == 'all':\n","            cm_normalized = cm.astype(float) / cm.sum()\n","        else:\n","            raise ValueError(\"Unknown normalization type. Use 'true', 'pred', or 'all'.\")\n","        cm_normalized = np.nan_to_num(cm_normalized)\n","    return cm_normalized\n","\n","# class_labels = le.inverse_transform(np.unique(y_test))\n","\n","plt.figure(figsize=(20, 15))\n","sns.heatmap(\n","    normalize_confusion_matrix(cm, norm='true'),\n","    annot=True, fmt=\".2f\", cmap='Blues',\n","    xticklabels=class_labels,\n","    yticklabels=class_labels\n",")\n","\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('Actual Labels')\n","plt.title('Normalized Confusion Matrix MLP of imbalanced dataset')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKx_0S-6Hxjp","outputId":"fa65f13d-4f09-452d-c725-fe7b0ee3fbe6"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 648x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["mlp = [0.9621027137553848,\n"," 0.9631583238703694,\n"," 0.9621027137553848,\n"," 0.9622934248321233]\n","\n","lgbm =[0.9034204831953626,0.886, 0.88,0.883]\n","svm= [0.9166, 0.897, 0.899, 0.898]\n","\n","index = ['Accuracy','Precision','Recall','F1']\n","df = pd.DataFrame({'MLP': mlp,\n","                   'LGBM': lgbm,\n","                   'SVM': svm}, index=index)\n","\n","\n","fig, ax = plt.subplots(figsize=(9, 4))\n","df.plot(kind='bar', ax=ax, rot=0)\n","ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76igX1iaHxjq"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qW1buVEuHxjq","outputId":"2c6ff81d-c144-43f9-b15c-c6c7f331c02e"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAArwAAAENCAYAAADtxLYOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArmElEQVR4nO3de1yUZf7/8ffMgAcOykFAUNGVSslDauama9mqBSoKD0sxsraDlNZqmVqa5aGMMms70EFlFTU8FKYiSOq3bLXMNA03lKxWMS0RFDwAGgzD/P7w12ysmqAw4M3r+dfMfV/3fX3uuQZ9c3HNPSa73W4XAAAAYFDm2i4AAAAAqEkEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABiaUwLv7Nmz1bdvX7Vr104//PDDBdvYbDbNnDlT/fv31+23367k5GRnlAYAAACDc0rg7devn5YuXaoWLVpctE1qaqoOHTqkjRs36oMPPlB8fLx+/vlnZ5QHAAAAA3NxRifdu3e/ZJv09HQNGzZMZrNZPj4+6t+/v9avX69Ro0ZVqa8TJ4pVXs53aQAAcDUzm03y9nav7TJgEE4JvJWRk5OjoKAgx/PAwEAdPXq0yufhhwMAAAC/V2cCb3XJzy9ihhcAgKuc2WySr69HbZcBg6gzd2kIDAzUkSNHHM9zcnLUvHnzWqwIAAAARlBnZnjDw8OVnJysO+64QydPntQnn3yipUuX1nZZAACgjikvL9fhw4dVXFwsO3/UrfdMJsnd3V2tWrWS2XzhuVyT3V7zb5VZs2Zp48aNOn78uLy9veXl5aV169YpNjZW48aNU6dOnWSz2fT8889r69atkqTY2FhFR0dXuS+WNAAAcPX7oyUNeXl5Kiwslrd3M5lMdeaP1agldnu5CgqOq0kTd/n7+1+wjVMCrzMReAEAuPr9UeDdt+97+foGyMXF1clVoa4qK7OqoCBX7dq1u+B+fi0CAABXFZvNJoulzqzKRB1gsbiorMx20f0EXgAAcNUxmUy1XQLqkEu9H/j1yCB8vBrJ4nr1/2nHZrWq4OSvtV3GVcEoYy4x7lVhlHFnzKuGcf9jHp6N5epS/XN41rJyFRWerfbzwvkIvAZhcXXVyfXxtV3GFfMKHyuJ/wQrwyhjLjHuVWGUcWfMq4Zx/2OuLmat3HGs2s97Vw+/S7Z58MH7ZLWWymq16vDhQ2rbNkSSdN117fTcczMr1c+qVStVUvKr7r57ZJXqGz9+rCZMeEotW7aq0nE339xNmzZ9ITc3t0ofs2vXTsXHv65Fi2r3DlppaWu1devneumlOVU6jsALAABwmRYuXCJJOnLkiB54YKTef3/FeW3Kysrk4nLxyDV06F2X1ffrr1/9vwQ5C4EXAACgmkVFDdKQIVHaufNrtWjRQqNHP6bnnntGxcVFKi0tVa9evTV27BOSpISEuTp79qzGjRuvtLS12rhxvTw9PXXgwH55eHjq5ZfnyNe32QX7eO21NxUSco3GjIlV+/ahysrao5ycHEVH3y0/P38lJ6/QsWPHNHbsE+rX73bHsUuXLtGOHV/p1KlTGj367+rbt58kadq0qTp06KCsVqtatmylqVOnq0mTJhX6LSsr04QJ43Tq1CmVlJTo+us7aPLkZ+Xq6nrJ+hcvXqiNG9fLZDKpcePGmjdvocxms9atS9VHHyXLZiuTh4eHnnrqGbVu3UZWq1WvvTZb33yzS35+fmrd+k+XNR4EXgAAgBpw/PhxvfvufElSSUmJXn31Dbm5uamszKrHH39M27ZtVc+efznvuO++26ukpA8UENBccXEv6MMPV2jMmL9fsr+8vFy9994/lZ+fr7vuitSIETFKSFikvXv3aPLkiRUCr9lsVkLCIv3000HFxj6gLl26ysfHR08+OVFeXt6SpLlz39H77y/SY4+Nq9CPxWLR88/HqWlTL9ntdj3//DSlpqY4ZqovVv+6dan6/PPNmj9/odzdPXTq1EmZzWbt3v2NPv30/zR37j/VoEEDffnlVs2aNVMJCYlavfojHTlyRMuWfaiysjKNHj1KgYFBVR4LAi8AAEANGDhwkONxeXm54uPfUGbmv2W321VQkK8ff/zhgoG3c+cbFBDQXJLUsWMn7djxVaX669fvdpnNZvn5+alp06a67ba+kqT27UN17FieSkpK1LBhQ0nS4MFRkqTWrduoXbv22rMnU7fe2kfp6eu0YUO6ysrKdPbsWQUHB5/XT3l5uZYufV/btm1VeXm5Tp8+rUaNGl2y/q1bP9fQocPk7n7u/spNm3pJkj7/fIt+/PEHPfTQfZIku92uwsJCSdKuXV9r4MAIubi4ysXFVeHhA/Xvf++u1OvxewReAACAGtC48X8/FLZ8eZIKC09rwYIlatiwoV566QWVlJRc8LgGDRo6HpvNZtlsF7+/bMXjGlQ47rfnFotFki56HrvdLpNJ2r37G61alayEhEXy9vbWhg0fa82aVee137jxY/373xmaO3eB3N3dtWjRAh06dOiS9V/8u87sGjw4Ug8/PKZS13k5uA8vAABADSssLFSzZs3UsGFD5eXlacuWzbVaT1raWknSoUOH9OOPP6hDh04qLCyUh4eHmjZtqtLSUqWmplzw2MLCInl5ecvd3V1FRYXauHF9pfrs3ftWrVqVrOLiYknSqVMnHdvT09OUl5cr6Vww37cvS5LUvftNWr9+ncrKyvTrr79Wuq//xQwvAAC4qlnLyit1C7HLOW91GT58hKZOfVr33Xe3/P0DdNNNPart3JejQQNXxcY+oFOnTurpp6fKx8dHPXv+RevXpys6eqj8/f3Vvv31ysrae96xAwcO0pYt/9Ldd98lPz9/3XBD14vOVlc8LkLHjuVp1Ki/yWKxyM3NXXPn/lNdu96o0aMf08SJ41VebpPValW/frerffvrFRV1p/7znx8VEzNM/v7+6tq1m44cOVLl6zXZLz6/fFXKzy9SebmhLqlS/Pw8DXOPxmPHCmu7jKuCUcZcYtyrwijjzphXTX0cd7PZJF9fjwvu27s3S0FBrauzNBjAkSM/qUOH6y+4jyUNAAAAMDQCLwAAAAyNwAsAAABD40NrqHe8vN3l6sLvegAA1Bf1PvASfuofVxezVu44VttlXLGa+ESykfGzXv8w5gB+U+8DL+EHqB/4Wa9/jDLmEuMOXKl6H3gBAMDVrYlnA1lcXKv9vLYyq04Xlv5hmwcfvE9Wa6msVqsOHz6ktm1DJEnXXddOzz03s1L9rFq1UiUlv+ruu0dWqb6oqEF67bU3FRJyTaWPOXLkiB54YKQ2bNhUpb6q265dOxUf/7oWLVrqlP4IvAAA4KpmcXGtkfsUe4WPlfTHgXfhwiWS/hsk339/xXltysrK5OJy8cg1dOhdV1QnLo3ACwAAUM2iogZpyJAo7dz5tVq0aKHRox/Tc889o+LiIpWWlqpXr94aO/YJSVJCwlydPXtW48aNV1raWm3cuF6enp46cGC/PDw89fLLc+Tr2+yC/WzY8LG+/Xa3jh8/pujoGA0bNkKS9NZbrysjY5esVqu8vLw0dep0BQYGnXf8tGlTdejQQVmtVrVs2UpTp05XkyZNtGvXTr3xxqvq0KGjMjO/lclk0gsvvKQ//amtJCk1dY0++GC5JMnV1VWvvvqmfH199eWXXygxcYFKS0vk6uqqJ56YoI4dO0uS5s59R598skF+fv66/voO1f2S/yECLwAAQA04fvy43n13viSppKREr776htzc3FRWZtXjjz+mbdu2qmfPv5x33Hff7VVS0gcKCGiuuLgX9OGHKzRmzN8v2EdBQb7mzl2g/Px8/e1vd6tLl2669trrdN9992vcuPGSpJSU1Xrnnbc0a9bL5x3/5JMT5eXlLelcIH3//UV67LFxkqQDBw7o2WdnaPLkZ5WY+E8lJi7Q88+/qF27dmrx4oWaN2+hfH2b6cyZM7JYLPr558NauDBBb775jtzdPXTgwH6NHz9WKSnp+vzzzfr8881asmSFGjZsqKeeerJaXuPKIvACAADUgIEDBzkel5eXKz7+DWVm/lt2u10FBfn68ccfLhh4O3e+QQEBzSVJHTt20o4dX120j8GDoyRJvr6+6tXrFn3zzS5de+112rZtq1au/FBnz56VzWa76PHp6eu0YUO6ysrKdPbsWQUHBzv2tW7dWu3atXfU8cUXWyRJX375uQYMiHDMOru5uUmSvvpqm3755WeNHj3KcQ6brUz5+fnatWun+ve/w9F2yJAoJSb+8+IvXjUj8AIAANSAxo3dHI+XL09SYeFpLViwRA0bNtRLL72gkpKSCx7XoEFDx2Oz2fyHgfX37Ha7TCaTcnKO6I03/qHExPcVFNRC3377b02b9sx57Xfv/karViUrIWGRvL29tWHDx1qzZtXv6mjwuzosjjrs9otWoJtv7qXp01+44L7axA0KAQAAalhhYaGaNWumhg0bKi8vT1u2bK6W865blypJOnHihL76aqu6dbtRxcXFcnV1kY+Pr8rLy7V69cqL1uTh4aGmTZuqtLRUqakpleqzd+9b9fHHacrPz5cknTlzRqWlperRo6e++upLHTiw39E2K2uvJKl79x769NP/c8w4p6WtvZLLrjJmeAEAwFXNVmb9/3dUqP7zVpfhw0do6tSndd99d8vfP0A33dSjWs7bvHlzPfLIg8rPP6777ntA11xzrSSpb9/bFRMzTAEBzdWtWzdlZHxz3rE9e/5F69enKzp6qPz9/dW+/fWOgPpHunW7Uffd96DGjRsjk8mkBg0aaM6cNxQcHKwZM2bpxRdnqqSkRFarVZ07d9H113dQ7963KjPzW9177wj5+fmpW7fuOnYsr1peg8ow2e0Xn5i+GuXnF6m8vPKX5OfnaYgbk9/Vw69GbsnibF7hY3XsWGGN9sGY1z2Me+UZZdwZ86qpj+NuNpvk6+txwX1792YpKKh1dZYGAzhy5Cd16HD9BfexpAEAAACGRuAFAACAoRF4AQDAVcdgKzJxhS71fiDwAgCAq4rFYpHNVlbbZaAOsdnK5OJiueh+Ai8AALiq+Ph46/TpE7Lby2u7FNQBdnu5Tp06IW9v74u24bZkAADgqtKsWTOdPXtWR48e/oMvQUB9YTJJ7u7uatas2UXbEHgBAMBVxWw2q3VrbkuGynNa4M3OztbkyZN18uRJeXl5afbs2WrTpk2FNvn5+ZoyZYpycnJktVp1880369lnn5WLC7kcAAAAl8dpa3inT5+umJgYbdiwQTExMZo2bdp5bebOnauQkBClpqYqNTVVe/fu1caNG51VIgAAAAzIKYE3Pz9fWVlZioiIkCRFREQoKytLBQUFFdqZTCYVFxervLxcpaWlslqtCggIcEaJAAAAMCinrBXIyclRQECALJZzt4uwWCzy9/dXTk6OfHx8HO0effRRjR07Vr1799bZs2d1zz336MYbb6xSXxf7GkJcPfz8PGu7BNQCxr3+YczrJ8YdtaFOLY5dv3692rVrp8WLF6u4uFixsbFav369wsPDK32O/PwilZdX/iOb/ODVPZX9nvXLxZjXTYx7/cOY10+VHXez2cQkFqqNU5Y0BAYGKjc3VzabTZJks9mUl5enwMDACu2SkpI0ZMgQmc1meXp6qm/fvtq+fbszSgQAAIBBOSXw+vr6KjQ0VGlpaZKktLQ0hYaGVljOIEktW7bUli1bJEmlpaXatm2brr32WmeUCAAAAINy2l0aZsyYoaSkJIWFhSkpKUkzZ86UJMXGxiozM1OS9Mwzz2jXrl0aPHiwoqKi1KZNGw0fPtxZJQIAAMCAnLaGNyQkRMnJyedtT0hIcDwODg5WYmKis0oCAABAPeC0GV4AAACgNhB4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGhOC7zZ2dmKjo5WWFiYoqOjdfDgwQu2S09P1+DBgxUREaHBgwfr+PHjzioRAAAABuTirI6mT5+umJgYRUZGKiUlRdOmTdOSJUsqtMnMzNTbb7+txYsXy8/PT4WFhWrQoIGzSgQAAIABOWWGNz8/X1lZWYqIiJAkRUREKCsrSwUFBRXaLVq0SA8++KD8/PwkSZ6enmrYsKEzSgQAAIBBOWWGNycnRwEBAbJYLJIki8Uif39/5eTkyMfHx9Fu//79atmype655x6dOXNGt99+u8aMGSOTyVTpvnx9Paq9fjiXn59nbZeAWsC41z+Mef3EuKM2OG1JQ2XYbDZ9//33SkxMVGlpqUaNGqWgoCBFRUVV+hz5+UUqL7dXuj0/eHXPsWOFNXp+xrxuYtzrH8a8fqrsuJvNJiaxUG2csqQhMDBQubm5stlsks4F27y8PAUGBlZoFxQUpPDwcDVo0EAeHh7q16+fvv32W2eUCAAAAINySuD19fVVaGio0tLSJElpaWkKDQ2tsJxBOre294svvpDdbpfVatVXX32l9u3bO6NEAAAAGJTTbks2Y8YMJSUlKSwsTElJSZo5c6YkKTY2VpmZmZKkQYMGydfXVwMHDlRUVJSuueYa3XXXXc4qEQAAAAbktDW8ISEhSk5OPm97QkKC47HZbNaUKVM0ZcoUZ5UFAAAAg+Ob1gAAAGBoVZrh3bp1q9atW6eCggLNnTtXmZmZKioqUs+ePWuqPgAAAOCKVHqG9/3339eMGTPUpk0bff3115KkRo0a6c0336yx4gAAAIArVenAu3jxYiUmJurhhx+W2XzusLZt2yo7O7vGigMAAACuVKUDb3FxseO+ub9981lZWZlcXV1rpjIAAACgGlQ68N50002aP39+hW1LlizRn//852ovCgAAAKgulf7Q2rPPPqvRo0crOTlZxcXFCgsLk4eHh+bOnVuT9QEAAABXpFKBt7y8XPv379eyZcv0ww8/6JdfflFgYKA6d+7sWM8LAAAA1EWVCrxms1mPPvqoMjIy1LlzZ3Xu3Lmm6wIAAACqRZXW8O7evbsGSwEAAACqX6XX8AYFBSk2Nlb9+vVT8+bNHXdqkKTHH3+8RooDAAAArlSlA29JSYn69+8vScrNza2xggAAAIDqVOnA+9JLL9VkHQAAAECNqHTglaSDBw8qLS1NeXl58vf3V0REhNq0aVNDpQEAAABXrtIfWtu0aZOGDh2q7OxsNW3aVNnZ2brzzjv16aef1mR9AAAAwBWp9Azv66+/rnfffVc333yzY9v27dv1wgsvqF+/fjVSHAAAAHClKj3De/ToUXXv3r3CthtvvFFHjx6t9qIAAACA6lLpwNu+fXstXLiwwrbExESFhoZWe1EAAABAdan0koYZM2ZozJgxWrJkiQIDA5WTkyM3Nze99957NVkfAAAAcEUqHXhDQkKUnp6u3bt3O+7ScMMNN8jV1bUm6wMAAACuSKUD73fffScvL68K63hzcnJ06tQptW/fvkaKAwAAAK5UpdfwTpo0SWVlZRW2Wa1WTZo0qdqLAgAAAKpLpQPvkSNH1KpVqwrbgoOD9csvv1R7UQAAAEB1qXTgbd68ufbu3Vth2969e+Xv71/tRQEAAADVpdJreO+//349+uijGjVqlIKDg/XTTz8pMTFRo0ePrsn6AAAAgCtS6cA7fPhweXp6auXKlcrNzVXz5s01efJkhYWF1WR9AAAAwBW55JKGPXv26IcffpAkDRgwQK+88oratWun3Nxcbd26VcXFxTVeJAAAAHC5Lhl44+LidPz4ccfz5557Tj/99JNGjBihH3/8UXPmzKnRAgEAAIArccnAu3//fse9d0+fPq3Nmzdrzpw5uueee/SPf/xDn332WY0XCQAAAFyuSwZem83m+Da13bt3y8/PT3/6058kSYGBgTp9+nTNVggAAABcgUsG3muuuUYff/yxJCk9PV09e/Z07MvNzZWnp2fNVQcAAABcoUvepWHixIkaM2aMZsyYIbPZrGXLljn2paenq1u3bjVaIAAAAHAlLhl4u3fvrs8++0wHDx5UmzZt5OHh4djXp08fDRw4sEYLBAAAAK5Epe7D6+HhoY4dO563vW3bttVeEAAAAFCdKv3VwlcqOztb0dHRCgsLU3R0tA4ePHjRtgcOHNANN9yg2bNnO6s8AAAAGJTTAu/06dMVExOjDRs2KCYmRtOmTbtgO5vNpunTp6t///7OKg0AAAAG5pTAm5+fr6ysLEVEREiSIiIilJWVpYKCgvPazp8/X7fddpvatGnjjNIAAABgcJVaw3ulcnJyFBAQIIvFIkmyWCzy9/dXTk6OfHx8HO327dunL774QkuWLNG77757WX35+npcuhHqND8/bnVXHzHu9Q9jXj8x7qgNTgm8lWG1WvXcc8/ppZdecgTjy5GfX6Tycnul2/ODV/ccO1ZYo+dnzOsmxr3+Yczrp8qOu9lsYhIL1cYpgTcwMFC5ubmy2WyyWCyy2WzKy8tTYGCgo82xY8d06NAhPfzww5LOfY2x3W5XUVGRXnjhBWeUCQAAAANySuD19fVVaGio0tLSFBkZqbS0NIWGhlZYzhAUFKTt27c7nsfHx+vMmTN6+umnnVEiAAAADMppd2mYMWOGkpKSFBYWpqSkJM2cOVOSFBsbq8zMTGeVAQAAgHrGaWt4Q0JClJycfN72hISEC7YfO3ZsTZcEAACAesBpM7wAAABAbSDwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNAIvAAAADA0Ai8AAAAMjcALAAAAQyPwAgAAwNBcnNVRdna2Jk+erJMnT8rLy0uzZ89WmzZtKrR55513lJ6eLovFIhcXF40fP1633HKLs0oEAACAATkt8E6fPl0xMTGKjIxUSkqKpk2bpiVLllRo07lzZz344INq3Lix9u3bp5EjR+qLL75Qo0aNnFUmAAAADMYpSxry8/OVlZWliIgISVJERISysrJUUFBQod0tt9yixo0bS5LatWsnu92ukydPOqNEAAAAGJRTZnhzcnIUEBAgi8UiSbJYLPL391dOTo58fHwueMyaNWsUHBys5s2bV6kvX1+PK64XtcvPz7O2S0AtYNzrH8a8fmLcURuctqShKnbs2KE333xTCxcurPKx+flFKi+3V7o9P3h1z7FjhTV6fsa8bmLc6x/GvH6q7LibzSYmsVBtnLKkITAwULm5ubLZbJIkm82mvLw8BQYGntc2IyNDkyZN0jvvvKO2bds6ozwAAAAYmFMCr6+vr0JDQ5WWliZJSktLU2ho6HnLGb799luNHz9eb731ljp06OCM0gAAAGBwTrsP74wZM5SUlKSwsDAlJSVp5syZkqTY2FhlZmZKkmbOnKlff/1V06ZNU2RkpCIjI/X99987q0QAAAAYkNPW8IaEhCg5Ofm87QkJCY7HH330kbPKAQAAQD3BN60BAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDQCLwAAAAyNwAsAAABDI/ACAADA0Ai8AAAAMDSnBd7s7GxFR0crLCxM0dHROnjw4HltbDabZs6cqf79++v2229XcnKys8oDAACAQTkt8E6fPl0xMTHasGGDYmJiNG3atPPapKam6tChQ9q4caM++OADxcfH6+eff3ZWiQAAADAgF2d0kp+fr6ysLCUmJkqSIiIi9MILL6igoEA+Pj6Odunp6Ro2bJjMZrN8fHzUv39/rV+/XqNGjap0X2azqcr1uTUwxsoOc2PP2i6hWlzOGFYVY173MO6VZ5RxZ8yrpr6NuzPeH6g/nBJ4c3JyFBAQIIvFIkmyWCzy9/dXTk5OhcCbk5OjoKAgx/PAwEAdPXq0Sn15e7tXub6BXXyrfExd1KTP/bVdQrXw9fWo8T4Y87qHca88o4w7Y141jDtw+Yzzqy8AAABwAU4JvIGBgcrNzZXNZpN07sNpeXl5CgwMPK/dkSNHHM9zcnLUvHlzZ5QIAAAAg3JK4PX19VVoaKjS0tIkSWlpaQoNDa2wnEGSwsPDlZycrPLychUUFOiTTz5RWFiYM0oEAACAQZnsdrvdGR3t379fkydP1unTp9WkSRPNnj1bbdu2VWxsrMaNG6dOnTrJZrPp+eef19atWyVJsbGxio6OdkZ5AAAAMCinBV4AAACgNvChNQAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagdeJTp06pU6dOunFF1+s7VLgJH379lV4eLiGDBmiiIgIrVu3rlrOm5mZqQkTJvxhm08//VSzZ8+ulv5QvX7/vhgwYICSk5OrvY+ff/5Zf/7znx3P27Vrp+Li4mrvB9Xrt/dGZGSkIiMjFRcXpy+++EJDhw5Vx44d+ZkGLpNLbRdQn6SmpqpLly5at26dJk2apAYNGtRYX2VlZXJxYXjrgrfeekvXXXedsrKyNGLECPXs2dPxpSuXO06dOnXSa6+99odt+vXrp379+l1Wzah5v70vfvjhBw0dOlS33nqrAgICarss1AG/vTd+89NPP2nWrFnasGGDSktLa7Ey4OpFInKijz76SE899ZTmzZunTZs2KTw8XLm5uZo1a5YOHjwoSYqIiNAjjzyiwsJCxcXFac+ePTKZTOrevbumTZumyZMnq2PHjho5cqQkVXg+efJkubu76+DBgzpx4oRWrVqlCRMmKDs7W1arVcHBwYqLi1PTpk0lSStXrtSSJUskSa6urpo3b57efvtttWrVSg899JAkKSsrS+PHj9f69etlMpmc/6IZyPXXXy93d3dNnjxZrVq1qjBOq1ev1rJly2Sz2eTh4aEZM2aobdu2kqR58+YpLS1NJpNJbm5uWrZsmb7++mvNnj1bq1atUn5+viZMmKD8/HxJUs+ePfXMM89o1apV+te//qW33npLkjR//nytXbtW0rnA/Oyzz8rd3V3x8fHKzs5WYWGhDh8+rODgYL355ptq3Lhx7bxQ9cx1112nJk2aKDc3V8XFxYqLi9OJEydktVr1t7/9TXfeeackKSMjQ6+88opjlvapp55S7969NXv2bO3YsUNWq1Xe3t6Ki4tTixYtavOSUM1at24t6dxfbQi8wOUh8DrJvn37dOrUKd188806duyYPvroI4WHh2vixInq06eP4uPjJUkFBQWSpLi4OLm5uSklJUVms9mx/VIyMjKUlJQkNzc3SdLUqVMds4mvv/66EhISNHHiRG3fvl3z5s3TsmXL5Ofnp+LiYrm4uOjee+/V6NGj9eCDD8pkMikpKUkxMTGE3Wrw1VdfqaSkRC4uLhXGaefOnfr444+1dOlSNWjQQJs3b9YzzzyjFStWaPXq1dq0aZOWL18uDw8PnThxQmZzxZVIqampCgoK0qJFiySdWzrzvzZv3qy1a9dqxYoVcnd319NPP613331XkyZNkiTt2bNHK1eulKenpx566CGlpqZq+PDhNf6aQNq1a5e8vb3Vvn17jRgxQnPmzFFISIiKiop05513qkuXLvL19dXf//53xcfHq1u3brLZbCoqKpJ07hspn376aUlScnKyXn31Vb3++uu1eUm4QuPGjVPDhg0lSRMnTtQtt9xSyxUBVz8Cr5OsXLlSkZGRMplMuuOOOzRr1iz98ssvysjIUGJioqPdb+H0s88+06pVqxzh5rftlxIeHu4Iu5KUkpKi1NRUWa1WnTlzRm3atJEk/etf/1JkZKT8/PwkSe7u7pKkkJAQtWrVSlu2bFGXLl20adMmTZky5Yqvvz777T8vDw8PxcfHO5a2/DZOmzZt0r59+zRs2DBJkt1u1+nTpyWdex/cfffd8vDwkCR5e3ufd/4bbrhBiYmJmj17tnr06KHevXuf12bbtm0aOHCg4zzDhw9XXFycY3/v3r3VpEkTSVLnzp116NChanwFcCHjxo2T3W7X4cOH9fbbb+vQoUPav3+/nnzySUcbq9WqAwcO6PDhwwoJCVG3bt0kSRaLxfGXmi1btmjZsmU6c+aMysrKauVaUL3+d0kDgCtH4HWC0tJSpaamqmHDhkpJSZF07j+y1atXV/lcFotF5eXljuclJSUV9v8+7O7cuVPLly/XihUr5OPjo9TUVH344YeX7OPee+/V8uXLtX//ft1xxx3y9PSscp34r//9zys1NbXCONntdt155516/PHHL+v8Xbt21Zo1a/Tll18qJSVF8+fP1/Llyyu0sdvtfzhL/9tsknTuPfa/7ytUv9/eFx9//LEmTZqk9957T97e3o5/I37vs88+u+A5fvnlF7300ktauXKlWrVqpW+++UYTJ06s6dIB4KrDXRqc4JNPPlHbtm21ZcsWbdq0SZs2bdLChQu1du1ade3a1fGnaOm/Sxr++te/asGCBbLb7RW2BwcHKzMzU5KUl5en7du3X7Tf06dPy8PDQ15eXiotLdVHH33k2PfXv/5VKSkpOn78uCSpuLjYsTasT58+ys7OVmJiomJiYqrvhcAF9e3bVykpKTp69KgkyWazac+ePZLOjdPy5csdf74+ceLEeccfPnxYHh4eGjRokKZMmaK9e/dW+KVIknr16qX09HQVFRXJbrdr5cqV6tWrVw1fGSpjwIAB+stf/qJPPvlEjRo10po1axz79u/fr6KiInXt2lX79+9XRkaGpHPvkVOnTqmoqEiurq7y8/NTeXm5VqxYUUtXAQB1GzO8TrBq1SoNHjy4wrauXbuqvLxcY8eO1aJFixQRESGz2ayIiAg9/PDDmjJliuLi4hQRESGLxaIePXro2Wef1fDhwzVu3DgNGTJEbdq0UefOnS/a76233qq1a9dqwIABCggIUMeOHR1huUePHnr44Yf1wAMPyGQyqUGDBpo7d66aNWsms9msqKgobdmyRe3bt6/R1wbSTTfdpCeeeEJjxoyRzWaT1WpVeHi4OnbsqKioKOXm5io6OloWi0Xu7u5aunRpheN37NihxMREx+z/zJkzz1vn26dPH33//fcaMWKEJKljx44aM2aM064Rf2zChAkaOnSo5s2bp/nz52vBggUqLy+Xr6+v3njjDfn4+Cg+Pl4vv/yyzpw5I7PZrKefflq9evVSeHi4Bg0apKCgIN10003auXNnbV8OqtnOnTv15JNPOn5hXbdunV588UXW9gJVYLL/NoUI/M4DDzyg4cOHa8CAAbVdCgAAwBVhSQMqyMzMVP/+/eXp6amwsLDaLgcAAOCKMcMLAAAAQ2OGFwAAAIZG4AUAAIChEXgBAABgaAReAIYwd+5cTZ06tbbLAADUQXxoDUCN6tu3r/Ly8rRly5YKX5EdGRmpffv26dNPP1XLli0vevz27ds1adIkbdmyxRnlAgAMiBleADWuRYsWWrduneP5999/r19//bXazl9WVlZt5wIAGA+BF0CNi4yMrPCVuWvWrFFUVJTjeWlpqWbPnq3bbrtNvXr10rRp0/Trr7/qzJkzio2NVV5enrp27aquXbsqNzdX8fHxGjdunCZOnKhu3bpp9erVio+P18SJEx3n3Llzp0aMGKHu3burT58+WrVqlSRp8+bNGjhwoLp27apbbrlFCxYscNbLAACoJQReADWuS5cuKioq0v79+2Wz2ZSenq4hQ4Y49s+ZM0fZ2dlas2aNNm7cqLy8PL3zzjtyc3NTQkKC/P39lZGRoYyMDAUEBEiSPv30U4WHh2vnzp3nfXX3kSNHFBsbq5EjR2rbtm1as2aNQkNDJUlTp07V888/r4yMDKWlpenmm2923gsBAKgVBF4ATvHbLO/WrVvVtm1bR3C12+1KTk7WM888Iy8vL3l4eOiRRx6psATiQrp06aL+/fvLbDarUaNGFfalpqaqV69eioiIkKurq7y9vR2B18XFRf/5z39UVFSkpk2bqkOHDjVzwQCAOsOltgsAUD9ERkZq5MiR+vnnnxUZGenYfuLECZ09e1ZDhw51bLPb7SovL//D8zVv3vyi+3JychQcHHzBfW+99Zbee+89vfbaa2rXrp0mTJigrl27VvFqAABXEwIvAKdo0aKFWrZsqc2bN+vFF190bPf29lajRo20bt06x6zv75lMpgue72LbJSkwMFDffvvtBfd17txZ7733nqxWq5YuXaonnnhCmzdvruLVAACuJixpAOA0L774ohYvXiw3NzfHNpPJpGHDhikuLk75+fmSpNzcXH3++eeSJF9fX508eVKFhYWV7mfw4MH68ssvlZ6errKyMp04cULfffedSktLtXbtWhUWFsrV1VXu7u6yWCzVe5EAgDqHwAvAaYKDg9WpU6fztk+aNEmtW7fW8OHD1a1bN91///3Kzs6WJIWEhGjQoEHq37+/unfvrtzc3Ev2ExQUpISEBCUmJqpHjx6KiorSvn37JEkpKSnq27evunXrphUrVuiVV16p3osEANQ5fPEEAAAADI0ZXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGgEXgAAABgagRcAAACGRuAFAACAoRF4AQAAYGj/Dxkhm/H0xA9mAAAAAElFTkSuQmCC","text/plain":["<Figure size 648x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train_b_new = [0.9010779584301114,\n"," 0.9014500228662894,\n"," 0.9010779584301114,\n"," 0.9009997698826618]\n","train_b = [0.9621027137553848,\n"," 0.9631583238703694,\n"," 0.9621027137553848,\n"," 0.9622934248321233]\n","index = ['Accuracy','Precision','Recall','F1']\n","df = pd.DataFrame({'Train ': train_b_new +train_b,\n","                   'model': ['Train imbalanced']*4 + ['Train balanced']*4, 'index':index*2})\n","\n","\n","fig, ax = plt.subplots(figsize=(9, 4))\n","# df.plot(kind='bar', ax=ax, rot=0)\n","\n","\n","sns.set_theme(style=\"darkgrid\", palette=\"pastel\")\n","sns.barplot(df, x=\"index\", y=\"Train \" , hue=\"model\")\n","ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n","# sns.label(x=\"Metrics\", y=\"Score\", color=\"\")\n","\n","ax.set_xlabel(\"Metrics\")\n","ax.set_ylabel(\"Score\")\n","\n","# Show plot\n","plt.show()\n","# plt.tight_layout()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GnauumOYHxjr"},"source":["[0.9602366347050999,\n"," 0.9608086944455532,\n"," 0.9602366347050999,\n"," 0.9603183029040747]\n","\n"," affine trên data balance và test bthg\n","\n","\n","\n"," Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.94      0.94      7567\n","           1       0.88      0.96      0.92      2036\n","           2       0.91      0.95      0.93      2096\n","           3       0.96      0.94      0.95      5276\n","           4       0.94      0.98      0.96      3788\n","           5       0.97      0.97      0.97      5417\n","           6       0.98      0.94      0.96      6716\n","           7       0.99      0.99      0.99      6667\n","           8       0.97      0.96      0.97      6250\n","           9       0.97      0.97      0.97      4560\n","\n","    accuracy                           0.96     50373\n","   macro avg       0.95      0.96      0.96     50373\n","weighted avg       0.96      0.96      0.96     50373"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_vLPUAlHxjs"},"outputs":[],"source":["# import numpy as np\n","# import plotly.graph_objects as go\n","\n","# # Sample data: Replace these with actual values\n","# classes = np.arange(1, 11)  # 10 classes from 1 to 10\n","# precision = np.random.uniform(0.7, 1.0, 10)  # Precision values (random example)\n","# accuracy = np.random.uniform(0.7, 1.0, 10)   # Accuracy values\n","# f1_score = np.random.uniform(0.7, 1.0, 10)   # F1-score values\n","\n","# # Define colors and labels\n","# metrics = {\n","#     \"Precision\": precision,\n","#     \"Accuracy\": accuracy,\n","#     \"F1 Score\": f1_score\n","# }\n","# colors = [\"red\", \"green\", \"blue\"]\n","\n","# # Create the 3D figure\n","# fig = go.Figure()\n","\n","# # Add each metric as a 3D line plot\n","# for i, (metric_name, values) in enumerate(metrics.items()):\n","#     fig.add_trace(go.Scatter3d(\n","#         x=classes,\n","#         y=[metric_name] * len(classes),  # Use metric name as categorical y-axis\n","#         z=values,\n","#         mode='lines+markers+text',\n","#         marker=dict(size=6, color=colors[i]),\n","#         line=dict(width=4, color=colors[i]),\n","#         text=[f\"{v:.2f}\" for v in values],  # Display values\n","#         textposition=\"top center\",\n","#         name=metric_name\n","#     ))\n","\n","# # Layout settings\n","# fig.update_layout(\n","#     title=\"3D Line Plot of Precision, Accuracy, and F1 Score\",\n","#     scene=dict(\n","#         xaxis_title=\"Class\",\n","#         yaxis_title=\"Metric\",\n","#         zaxis_title=\"Value\",\n","#         yaxis=dict(type=\"category\"),  # Make y categorical\n","#     ),\n","#     margin=dict(l=0, r=0, b=0, t=40)\n","# )\n","\n","# # Show plot\n","# # fig.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}